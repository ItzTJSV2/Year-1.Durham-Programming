{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook contains an excerpt from the [Whirlwind Tour of Python](http://www.oreilly.com/programming/free/a-whirlwind-tour-of-python.csp) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/WhirlwindTourOfPython).*\n",
    "\n",
    "*The text and code are released under the [CC0](https://github.com/jakevdp/WhirlwindTourOfPython/blob/master/LICENSE) license; see also the companion project, the [Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Preview of Data Science Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to spring from here and go farther in using Python for scientific computing or data science, there are a few packages that will make your life much easier.\n",
    "This section will introduce and preview several of the more important ones, and give you an idea of the types of applications they are designed for.\n",
    "\n",
    "If you are using Anaconda on your own machine and find you need to install these packages, then follow the instructions in the introductory section of notebook 6.1. All of these packages are already available for you to try using on NCC.\n",
    "\n",
    "Let's take a brief look at each of these in turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy: Numerical Python\n",
    "\n",
    "NumPy provides an efficient way to store and manipulate multi-dimensional dense arrays in Python.\n",
    "The important features of NumPy are:\n",
    "\n",
    "- It provides an ``ndarray`` structure, which allows efficient storage and manipulation of vectors, matrices, and higher-dimensional datasets.\n",
    "- It provides a readable and efficient syntax for operating on this data, from simple element-wise arithmetic to more complicated linear algebraic operations.\n",
    "\n",
    "In the simplest case, NumPy arrays look a lot like Python lists.\n",
    "For example, here is an array containing the range of numbers 1 to 9 (compare this with Python's built-in ``range()``):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.arange(1, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy's arrays offer both efficient storage of data, as well as efficient element-wise operations on the data.\n",
    "For example, to square each element of the array, we can apply the \"``**``\" operator to the array directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike Python lists (which are limited to one dimension), NumPy arrays can be multi-dimensional.\n",
    "For example, here we will reshape our ``x`` array into a 3x3 array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = x.reshape((3, 3))\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A two-dimensional array is one representation of a matrix, and NumPy knows how to efficiently do typical matrix operations. For example, you can compute the transpose using ``.T``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or a matrix-vector product using ``np.dot``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(M, [5, 6, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and even more sophisticated operations like eigenvalue decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.eigvals(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such linear algebraic manipulation underpins much of modern data analysis, particularly when it comes to the fields of machine learning and data mining.\n",
    "\n",
    "We'll see many more details on NumPy in a future topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas: Labeled Column-oriented Data\n",
    "\n",
    "Pandas is a much newer package than NumPy, and is in fact built on top of it.\n",
    "What Pandas provides is a labeled interface to multi-dimensional data, in the form of a DataFrame object that will feel very familiar to users of R and related languages. You might find it easiest to think about a DataFrame as something akin to an Excel spreadsheet where you can label each of the rows and columns.\n",
    "DataFrames in Pandas look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'label': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'value': [1, 2, 3, 4, 5, 6]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas interface allows you to do things like select columns by name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply string operations across string entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply aggregates across numerical entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, perhaps most importantly, do efficient database-style joins and groupings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('label').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here in one line we have computed the sum of all objects sharing the same label, something that is much more verbose (and much less efficient) using tools provided in Numpy and core Python.\n",
    "\n",
    "Again, we'll see many more details on Pandas in a future topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib MatLab-style scientific visualization\n",
    "\n",
    "Matplotlib is currently the most popular scientific visualization packages in Python.\n",
    "Even proponents admit that its interface is sometimes overly verbose, but it is a powerful library for creating a large range of plots.\n",
    "\n",
    "To use Matplotlib, we can start by enabling the inline mode (for use in the Jupyter notebook) and then importing the package as ``plt``\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can run this if using Jupyter notebook for interactive graphs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')  # make graphs in the style of R's ggplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create some data (as NumPy arrays, of course) and plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10)  # range of values from 0 to 10\n",
    "y = np.sin(x)           # sine of these values\n",
    "plt.plot(x, y);         # plot as a line\n",
    "plt.show()              # show the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create interactive plots that we can pan and zoom for example. To do this we need to ensure we have the ipympl package installed to work with our Jupyterlab environment, and then we can use the widget mode as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10)  # range of values from 0 to 10\n",
    "y = np.sin(x)           # sine of these values\n",
    "plt.plot(x, y);         # plot as a line\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run this code live, you will see an interactive plot that lets you pan, zoom, and scroll to explore the data.\n",
    "\n",
    "This is the simplest example of a Matplotlib plot; for ideas on the wide range of plot types available, see [Matplotlib's online gallery](http://matplotlib.org/gallery.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciPy: Scientific Python\n",
    "\n",
    "SciPy is a collection of scientific functionality that is built on NumPy.\n",
    "The package began as a set of Python wrappers to well-known Fortran libraries for numerical computing, and has grown from there.\n",
    "The package is arranged as a set of submodules, each implementing some class of numerical algorithms.\n",
    "Here is an incomplete sample of some of the more important ones for data science:\n",
    "\n",
    "- ``scipy.fftpack``: Fast Fourier transforms\n",
    "- ``scipy.integrate``: Numerical integration\n",
    "- ``scipy.interpolate``: Numerical interpolation\n",
    "- ``scipy.linalg``: Linear algebra routines\n",
    "- ``scipy.optimize``: Numerical optimization of functions\n",
    "- ``scipy.sparse``: Sparse matrix storage and linear algebra\n",
    "- ``scipy.stats``: Statistical analysis routines\n",
    "\n",
    "For example, let's take a look at interpolating a smooth curve between some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "\n",
    "# choose eight points between 0 and 10\n",
    "x = np.linspace(0, 10, 8)\n",
    "y = np.sin(x)\n",
    "\n",
    "# create a cubic interpolation function\n",
    "func = interpolate.interp1d(x, y, kind='cubic')\n",
    "\n",
    "# interpolate on a grid of 1,000 points\n",
    "x_interp = np.linspace(0, 10, 1000)\n",
    "y_interp = func(x_interp)\n",
    "\n",
    "# plot the results\n",
    "plt.figure()  # new figure\n",
    "plt.plot(x, y, 'o')\n",
    "plt.plot(x_interp, y_interp);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see is a smooth interpolation between the points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Data Science Packages\n",
    "\n",
    "Built on top of these tools are a host of other data science packages, including general tools like [Scikit-Learn](http://scikit-learn.org) for machine learning and [Scikit-Image](http://scikit-image.org) for image analysis, as well as more domain-specific packages like [AstroPy](http://astropy.org) for astronomy and astrophysics, [NiPy](http://nipy.org/) for neuro-imaging, and many, many more.\n",
    "\n",
    "No matter what type of scientific, numerical, or statistical problem you are facing, it's likely there is a Python package out there that can help you solve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is everything for this topic, I hope this overview of functions, tools and packages for data science applications has been useful. You likely won't need all of these packages during this year, but in the years that follow, depending on which Computer Science modules you choose to take, you will definitely find yourself using the majority of them.\n",
    "\n",
    "Head over to the final notebook of this topic and attempt the exercises. These will test your understanding of the content from this topic, but also build on content you've seen previously to make sure you are practicing using the core tools and techniques. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
